# Shared-Memory Synchronization

Michael L. Scott

### 1. 原子性和条件同步

实际上，现实程序中几乎所有的同步模式（即所有对可接受的交错执行的概念上的约束）都可以看作是原子性或条件同步的实例。

原子性确保指定的指令序列在参与任何可能的交互时，是一个不可分割的整体，即在执行过程中不会出现任何其他操作（请注意，交错的概念本身就是基于底层机器指令是原子性的假设）。

条件同步可确保在某些必要的前提条件成立之前，不会发生指定的操作。通常，这个先决条件是在其他线程中完成某些操作。

### 2. 安全性和活性

无论是基于自旋还是阻塞，正确的同步实现都需要安全性和活性。

非正式地说，安全性意味着坏的事情一定不会发生；活性意味着好的事情总会发生。

### 3. 顺序一致性和可串行性

如果说并发对象 O 的实现是顺序一致的，则必须满足：在任意可能的执行中，在对象 O 上操作的（有相同的输入输出）全局次序，与每个线程中的程序顺序是一致的。

不幸的是，顺序一致性缺乏可组合性，这限制其对高级并发对象的用途。

多对象原子操作是数据库系统的基本特征，被称之为事务。

对数据库和内存而言，最简单的排序标准叫作可串行性。如果事务之间按照某种全局次序依次执行，而具有相同的执行效果，就说这些事务是可串行化的。

判断给定的事务集合是否可串行化是 NP-难问题。好在实际中我们不需要这样做，我们只需使用全局锁（或细粒度锁）或非阻塞方式来保证可串行化就行。

顺序一致性和可串行性相似，都有一个共同的弱点：缺乏线程可观察到的其他顺序所需的一致性。

它们的区别仅仅在于，事务需要能够访问动态选择的一组对象，而顺序一致性仅限于特定的单对象的一组操作。

事实证明，两阶段锁定足以确保严格的可串行性，但其他某些“普通”可串行性的实现则不能。

### 4. 可组合性

为了避免混淆，我们使用“可组合性”一词来表示我们可以将单独对象上的操作顺序合并（组合）成一个相互一致的顺序。

在数据库和事务内存中，“可组合性”意味着我们可以组合单个原子操作变为更大的、仍然是原子的（即可串行化的）操作。

### 5. 非阻塞演进

考虑到难以衡量程序的执行速度（比如存在分时、缓存丢失、页面故障或其他异常情况），我们通常使用抽象程序的执行步骤，而不是绝对时间来衡量演进性。

非阻塞演进特性由弱至强可分为 3 种：

无障碍（obstruction free）：只要存在某段时间，只有当前线程单独执行，就能保证在有限步骤内完成。
无锁（lock free）：至少存在一个线程的执行，保证在有限步骤内完成。无锁意味着无活锁（ livelock freedom）。
无等待（wait free）：所有线程的执行，保证在有限步骤内完成。无等待意味着无饥饿（starvation freedom）。

无等待算法明显不常见。Herlihy 证明了任何顺序数据结构都可以自动转换为无等待的并发版本，但构建效率低下。Kogan 和 Petrank 最近的工作（建立在一系列中间结果的基础上）展示了如何显著地减少时间开销（Fast-Path-Slow-Path），尽管空间开销仍然与系统中的最大线程数量成正比。

一般无锁或无等待算法都需要帮助机制：即其他线程在必要时帮助当前线程完成执行。

### 6. 原子对象层次结构

Herlihy 建议，将这些原语（更确切地说，这些原语操作的对象）根据它们可以实现无等待共识的线程数量进行分类。

事实上，我们可以定义一个无限的原子对象层次结构，其中那些出现在 k 级的原子对象可以实现 k 个线程的无等待共识（但不能实现 k+1 个线程的无等待共识）。

原子寄存器（原子读写）的共识数为 1；

TAS，FAI，FAA 等 RMW 类型的原子指令的共识数为 2；

CAS 与 LL/SC 的共识数为无穷（意味着 CAS 可以实现任意线程数的无等待共识）。

### 7. Peterson 锁算法

Peterson 2-线程自旋锁算法，self 变量初始化为 0 或 1。

算法使用 2 种变量，一是 turn，表明当前“留守”的线程；另一个是 interested 数组，用于线程表明获取锁的意愿（自己写别人读）。

加锁时，首先表明自己希望获得锁（将 interested 的值置为 true），然后“谦让”一下，表明自己愿意留守（把获取锁的机会让给另一个线程）。之后开始自旋，要么另一个线程不想获取锁，要么当前的留守线程不是自己时，获得锁。

解锁时，表明自己不希望获得锁（将 interested 的值置为 false）即可。

Peterson 算法是无死锁，互斥，公平的加锁算法。

Peterson 算法可以很容易的扩展为 n-线程自旋锁算法。

```java
class lock
    (0, 1) turn
    bool interested[0..1] := { false, false }

lock.acquire():
    other := 1-self
    interested[self].store(true)
    turn.store(self)
    while interested[other].load() and turn.load() ≠ other; // spin
    fence(||RW)

lock.release():
    interested[self].store(false, RW||)
```

### 8. Lamport 的 Bakery 锁算法

面包店算法类似于面包店排队，首先获得一个编号（取号），然后按照编号依次获得服务（操作）。

每个线程首先扫描编号数组，以期获得当前“最大”的编号（不同线程取号可能相同，但是可以定义一个偏序关系）。

在扫描过程中，它将其选择标志设置为 true，以便让其他线程知道此事。

扫描结束后，再次扫描数组，自旋直到其他线程
（1）取号结束
（2）不取号或取的号大于等于自己

在当前线程确定自己的编号是所有线程中最小的时候，就可以进入临界区了（此时处于队列头部）。

解锁时，表明自己不取号就完了。

```java
class lock
    bool choosing[T ] := { false … }
    int number[T ] := { 0 … }

lock.acquire():
    choosing[self].store(true, ||R)
    int m := 1 + max (number[i])
    number[self].store(m, R||)
    choosing[self].store(false)
    for i in T
        while choosing[i].load();// spin
        repeat
            int t := number[i].load() // spin
        until t = 0 or <t,i> >= <m,self>
    fence(||RW)

lock.release():
    number[self].store(0, RW||)
```

### 9. Lamport 的快速锁算法

该算法的核心是一对锁字段，x 和 y。

要获得锁，线程 t 必须将其 id 写入 x，然后写入 y，并确保中间没有其他线程写入 x。

线程 t 在写 x 后立即检查 y，在写 y 后立即检查 x。如果检查 y 时不是初始状态，则存在其他线程进入临界区，线程 t 等待其离开临界区并重试。如果检查 x 时不是 t，则其他一些线程可能已进入临界区（t 不能确定）；在这种情况下，t 必须等到竞争线程注意到冲突或离开临界区。

为了实现其“注意冲突”机制，快速锁使用了一组尝试标志，每个线程一个。

每个线程在争夺锁时设置自己的标志（即使在临界区，没有争用的情况下也保持该设置）。如果一个线程 t 确实检测到争用，它会取消它的尝试标志，等待整个数组被清除，然后检查它是否是最后一个要设置 y 的线程。如果是，则进入临界区。如果没有，它将重试获取锁逻辑。

快速锁是互斥的，无死锁的，但不是无饥饿的。

```java
class lock
    T x
    T y := ⊥
    bool trying[T] := { false … }

lock.acquire():
    loop
        trying[self].store(true)
        x.store(self)
        if y.load() ≠ ⊥
            trying[self].store(false)
            while y.load()≠ ⊥; // spin
            continue // go back to top of loop
        y.store(self)
        if x.load() ≠ self
            trying[self].store(false)
            for i in T
                while trying[i].load(); // spin
            if y.load() ≠ self
                while y.load() ≠ ⊥ // spin
                continue // go back to top of loop
        break
    fence(||RW)

lock.release():
    y.store(⊥, RW||)
    trying[self].store(false)
```

### 10. Ticket 锁算法

和 Lamport 的 Bakery 算法一样，互相争用的线程以先来先得的次序获得锁。

与 Bakery 算法不同的是，由于使用 FAI 原子指令，算法的空间复杂度是常数。时间复杂度与争用的线程成正相关，是线性复杂度。

注意：争用的线程数只要不超过 next_ticket 所能标识的最大值，next_ticket 溢出就不是问题 。

```java
class lock
    int next_ticket := 0
    int now_serving := 0
    const int base = ... // tuning parameter

lock.acquire():
    int my_ticket := FAI(&next_ticket)
    // returns old value;
    // arithmetic overflow is harmless
loop
    int ns := now_serving.load()
    if ns = my_ticket
        break
    pause(base x (my_ticket-ns))
    // overflow in subtraction is harmless
fence(||RW)

lock.release():
    int t := now_serving + 1
    now_serving.store(t, RW||)
```

### 11. MCS 锁算法

获取锁时，先分配一个新的 qnode，初始化其下一个指针为 null，并将其交换到队列的尾部。

如果交换返回的值为空，则调用线程已获得锁。

如果交换返回的值为非空，则需要将自己加入队列，并在自己的 waiting 上自旋。

释放锁时，如果没有后继，则使用 CAS 将 tail 还原。否则，设置后继的 waiting 为 false，唤醒后继。

MCS 锁具有几个重要特性：线程以无等待的方式（使用交换）加入队列，之后它们按 FIFO 顺序获得锁。每个等待的线程都在自己的本地变量上自旋，没有资源争用问题。锁传递的时间复杂度是常数，空间复杂度与线程数成线性关系。

加锁时，可以使用 CAS 替代 SWAP，但入队的非阻塞演进特性会由无等待降为无锁。

解锁时，也可使用 SWAP 替代 CAS，但会失去 FIFO 特性，不再具有公平性。

MCS 算法的变种在加锁解锁时，可以消除入参（除了锁本身之外没有其他参数）。

```java
type qnode = record
    qnode* next
    bool waiting
class lock
    qnode* tail := null
lock.acquire(qnode* p): // Initialization of waiting can be delayed
    p->next := null // until the if statement below,
    p->waiting := true // but at the cost of an extra W||W fence.
    qnode* prev := swap(&tail, p, W||)
    if prev ≠ null // queue was nonempty
        prev->next.store(p)
        while p->waiting.load(); // spin
    fence(||RW)
lock.release(qnode* p):
    qnode* succ := p->next.load(WR||)
    if succ = null // no known successor
        if CAS(&tail, p, null) return
        repeat succ := p->next.load() until succ ≠ null
    succ->waiting.store(false)
```

### 12. CLH 锁算法

MCS 算法加锁时在当前节点上自旋，解锁时修改后继节点；而 CLH 算法加锁时在前驱节点上自旋，解锁时修改当前节点。

MCS 算法在解锁时可能需要等待后继节点出现，这一步是阻塞的，而 CLH 算法无此问题。

在原始论文中，CLH 锁有两个版本：一个简单的“LH”锁和一个增强的“M”锁。M 锁在没有其他线程试图获得锁时，允许线程保留原来的 qnode 节点，从而减少了缓存丢失的次数。M 锁需要 CAS 来解决当前线程释放（在此之前无竞争）锁时出现其他线程获取锁的竞态条件。LH 锁没有这样的竞态条件，它所需要的就是 SWAP 指令。

扩展 CLH 锁算法，可以得到不同优先级次序的队列锁，而不仅仅是 FIFO。除此之外，通过将节点标记为废弃节点，并在释放锁时跳过它们，可以实现超时（获取锁时可以增加超时参数）。

```java
type qnode = record
    qnode* prev // read and written only by owner thread
    bool succ_must_wait
class lock
    qnode dummy := { null, false }
    // ideally, dummy and tail should lie in separate cache lines
    qnode* tail := &dummy
lock.acquire(qnode* p):
    p->succ_must_wait := true
    qnode* pred := p->prev := swap(&tail, p, W||)
    while pred->succ_must_wait.load(); // spin
    fence(||RW)
lock.release(qnode** pp):
    qnode* pred := (*pp)->prev
    (*pp)->succ_must_wait.store(false, RW||)
    *pp := pred // take pred’s qnode
```

在这里，MCS 和 CLH 锁之间的选择取决于架构特性和成本。MCS 锁的空间需求较低，但对于某些机器上的 CLH 锁，性能可能更好。

### 13. 锁的扩展

加锁时期望有过期时间，即 tryLock。在指定时间内如未能获得锁，则不再参与锁的获取。

期望锁是可重入的，即 reentrant。持有锁的线程可再次获得锁。当然解锁的次数与加锁的次数一致，才真正释放锁。

锁还有一些特殊的用法，比如锁的局部性：TTAS 的性能比 TAS 的性能要好。

双重校验加锁：在延迟初始化耗时操作时，只需加锁一次。

偏向锁：已经获得锁的线程可能更应该获得锁。例如 JVM 对 synchronized 的优化。

### 14. 读写锁

读写锁最初由 Courtois 等人在 1971 年提出，它放松对互斥的限制，只要不做更新，允许多个线程同时访问同一个共享的数据结构。

Courtois 等人认为，读写锁的公平性取决于使用它的上下文：存在不同的公平性。

“读者优先”最大限度地减少了读者的延迟。它允许新到达的读者加入当前的一组读者之中，即使写者已经在等待，从而最大限度地提高了总吞吐量。

“写者优先”确保尽快地看到更新。它要求新到达的读者等待当前的写者或等待中的写者，即使有读者已经进入临界区，即使写者到达得比读者晚。

这两种优先允许任意延迟，意味着没有优先的线程可能饥饿。

第三种是读写公平锁。其中读者等待先到的写者；写者等待先到的读者和写者。

最近（2010 年）提出了第四种读写锁，即阶段公平锁。在阶段公平锁中，只要读者写者源源不断，则读者和作者交替获得锁。每个读者最多等待一个写者，而不是所有先到的写者。当写者退出临界区时，所有的读者都可以进入。新到达的读者在没有写者的情况下，可以加入当前的读者组，否则在第一个等待的写者之后等待。

| 锁的类型 | 处于临界区 | 下一个 | 操作                                         |
| -------- | ---------- | ------ | -------------------------------------------- |
| 读者优先 | 读者       | 读者   | 进入临界区                                   |
| 读者优先 | 读者       | 写者   | 等待，在队尾                                 |
| 读者优先 | 写者       | 读者   | 等待，在队头                                 |
| 读者优先 | 写者       | 写者   | 等待，在队尾                                 |
| 写者优先 | 读者       | 读者   | 等待，在队尾，没有写者则进入临界区           |
| 写者优先 | 读者       | 写者   | 等待，在所有读者之前，在已等待的写者之后     |
| 写者优先 | 写者       | 读者   | 等待，在队尾                                 |
| 写者优先 | 写者       | 写者   | 等待，在所有读者之前，在已等待的写者之后     |
| 读写公平 | 读者       | 读者   | 等待，在队尾，没有写者则进入临界区           |
| 读写公平 | 读者       | 写者   | 等待，在队尾                                 |
| 读写公平 | 写者       | 读者   | 等待，在队尾                                 |
| 读写公平 | 写者       | 写者   | 等待，在队尾                                 |
| 阶段公平 | 读者       | 读者   | 等待，在第一个写者之后，没有写者则进入临界区 |
| 阶段公平 | 读者       | 写者   | 等待，在队尾                                 |
| 阶段公平 | 写者       | 读者   | 等待，在队头                                 |
| 阶段公平 | 写者       | 写者   | 等待，在队尾                                 |
