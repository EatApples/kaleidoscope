# 服务端

### 服务端之间如何通信的

### 服务端之间如何感知彼此

重点来了，每个 nacos 服务器数是怎么保证 healthyList（server 列表）是一样的呢？

解决的办法仍然是心跳：

DistroMapper 初始化的时候会启动一个 ServerStatusReporter

ServerStatusReporter 会向其他的 nacos 服务器发送心跳，证明自己是健康的

ServerStatusReporter 的 run 方法的 finally 会继续调用自己，这样就相当于是个定时任务了。

如果一直没收到其他 nacos 服务器的心跳信息呢，这里就有个神奇的逻辑了：ServerStatusReporter 是会模拟发送心跳给自己，保证 healthyList 的逻辑一定会执行。

### 服务端如何保证高可用

### 服务端状态的转化逻辑

### 服务端之间如何保持数据一致性

那要如何保证数据的最终一致呢。

其实是通过心跳来保证的

leader 发送心跳的时候会带上所有的 key 和 key 对应的时间戳，follower 发现 key 不存在或者时间戳比较小，就发送请求给 leader 拿这些 key 的数据，最终达到数据一致。

这些数据会有点大，所以做了 gzip 压缩

follower 收到心跳的时候，判断 key 的存在和时间戳，和 leader 对不上的，发起请求拿最新的

不一致的 key 可能比较多，所以批量去拿，每次拿 50 个 key。

数据差距可能比较大，一直循环拿的话对 leader 的压力会比较大，所以拿一次之后 slepp 200ms。

HttpClient 异步去获取这些内容，异步回来可能是不同的线程，会有多线程的问题，所以要加锁。

当然这里 HttpClient 是同步请求，也会是要加锁的，因为收到心跳请求是不同的线程，如果心跳处理比较慢，也变成多线程处理了

上面的流程只是处理了 key 的新增和更新，那 key 的删除怎么同步呢？

本地的所有的 key 放到一个 map，处理过的 key 标记一下，如果到最后还有 key 没标记，说明是本地有，但是 leader 没有。这种 key 就是 leader 已经删除的 key 了。

### 服务元数据

### 客户端数据

### Nacos 中使用了 UDP 吗？作用是什么？

变化的通知 push 采用的是 udp，我觉得这种比 tcp 长连接好很多，比我们的 http longpoling 也要好，比 grpc 的 http/2 也要好。老实说通知真的不多，为什么当初我们就没想到用 udp。

push 用 udp 有什么不好的地方吗，不好地方就是 sdk 要开一个 udp 端口，感觉其实也还好吧。

### HostReactor 中的故障转移是怎么做的？

NacosNamingService 的 selectInstances()方法，我这里的 subscribe 值是 true，即代表我这个消费者直接订阅了这个服务，因此最终的信息是从本地 Map 中获取，即 Nacos 维护了一个注册列表。

再看下 HostReactor 的 getServiceInfo()方法：最终所需要的结果是从 serviceInfoMap 中获取，并且通过多个 Map 进行维护服务实例，若存在数据的变化，还会通过强制睡眠 5 秒钟的方式来等待数据的更新。

无论怎样都会调用 this.scheduleUpdateIfAbsent(serviceName, clusters)方法：

通过 scheduleUpdateIfAbsent()方法定时的获取实时的实例数据，并且负责维护本地的服务注册列表，若服务发生更新，则更新本地的服务数据。

### Nacos 中怎么判断实例是否过期，是只判断自己负责的那部分吗？

如果重复的做，会有很大的资源浪费，而且如果都检查到超时了，都和 leader 通信说要下线，对网络的负担也比较高。

解决的办法就是 服务名 hash % nacos 服务器数目 ，得到其中一台 nacos 服务器，如果是自己的话，就开始检查这个服务的实例列表，如果不是就跳过。

每个 nacos 服务器都这样去检查，自然会覆盖到所有服务的检查。

### 服务发现如何做心跳检查

方式一 tcp
方式二 http
方式三 mysql

# 客户端

### 客户端与服务端如何通信的

这里面逻辑有些多，我总结下，主要是启动了一个线程，每隔 30s，去执行 refreshSrvIfNeed()这个方法，

refreshSrvIfNeed()这个方法里面，做的事情，是通过一个 http 请求，去 Nacos server 获取一串 Nacos server 集群的地址列表

获取完地址列表后，赋值给 serversFromEndpoint，并且记录当前更新时间，在下一次更新时，小于 30s，就不更新，避免频繁更新，总的来说，NameProxy 的目的就是定时在客户端维护 Nacos 服务端的最新地址列表

### 客户端如何保证高可用

首先判定下容灾开关是否有，容灾开关是一个磁盘文件的形式存在，通过容灾开关文件名字，判定容灾开关是否打开，1 表示打开，0 为关闭，读取到容灾开关后，将值更新到内存中，后续解析地址列表时，首先会判定一下容灾开关是否打开，如果打开了，就读缓存的数据，否则从服务端获取最新数据。

概述下客户端初始化流程做的几件事：

- 初始化事件分发组件，用于处理服务端主动通知下来的变更数据
- 初始化 Nacos 服务集群地址列表更新组件，用于客户端维护 Nacos 服务端的最新地址列表
- 初始化服务健康检查模块，主动给服务端上报服务的健康情况
- 初始化客户端的缓存，10s 检查一次，如果没有，则创建
- 24 小时备份一次客户端的缓存文件
- 5s 检查一次容灾开关，更新到内存中，容灾模式情况下，服务地址读的都是缓存

经常有人说过，Nacos 有个好处，就是当一个服务挂了之后，短时间内不会造成影响，因为有个本地注册列表，在服务不更新的情况下，服务还能够正常的运转，其原因如下：

- Nacos 的服务发现，一般是通过订阅的形式来获取服务数据。
- 而通过订阅的方式，则是从本地的服务注册列表中获取（可以理解为缓存）。相反，如果不订阅，那么服务的信息将会从 Nacos 服务端获取，这时候就需要对应的服务是健康的。（宕机就不能使用了）
- 在代码设计上，通过 Map 来存放实例数据，key 为实例名称，value 为实例的相关信息数据（ServiceInfo 对象）。

### 客户端状态的转化逻辑
