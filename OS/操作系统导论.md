```
中文名：《操作系统导论》
英文名：《Operating Systems: Three Easy Pieces》
作者：Remzi H. Arpaci-Dusseau and Andrea C. Arpaci-Dusseau
英文版是免费开放的：http://pages.cs.wisc.edu/~remzi/OSTEP/
```

# 目录

不闻不若闻之，闻之不若见之，见之不若知之，知之不若行之——荀子

### 1. 操作系统为什么将资源虚拟化？

答案显而易见：让系统更易于使用。

操作系统将物理资源（CPU，磁盘，内存等）转换为更通用、更强大且更易于使用的虚拟形式。我们有时将操作系统称为虚拟机。

为了让用户使用虚拟机的功能，操作系统会提供系统调用。

操作系统有时被称为资源管理器，因为虚拟化让许多程序运行（从而共享 CPU），让许多程序可以同时访问各自的指令和数据（从而共享内存），让许多程序访问设备（从而共享磁盘等）

### 2. 操作系统实际上做了什么？

操作系统

（1）取得 CPU、内存、磁盘等物理资源，并对它们进行虚拟化。

（2）处理与并发有关的麻烦且棘手的问题。

（3）持久地存储文件，从而使它们长期安全。

这就是本书所讲的三个模块。

### 3. 操作系统设计目标

（1）抽象：建立一些抽象，让系统方便和易于使用（不用考虑底层）

（2）高性能：提供高性能，最小化操作系统的开销

（3）隔离/保护：在应用程序之间，应用程序与操作系统之间提供保护（也就是所谓的隔离）

（4）可靠性：应用程序都强依赖操作系统，操作系统必须不间断地运行，操作系统力求提供高度的可靠性

（5）高效，安全，可移植

### 4. 什么是系统调用？

系统调用将控制转移（跳转）到操作系统中，同时提高硬件特权级别。

用户应用程序以所谓的用户模式运行，这意味着硬件限制了应用程序的功能。例如，以用户模式运行的应用程序通常不能发起对磁盘的 IO 请求，不能访问任何物理内存页，或在网络上发送数据包。

在发起系统调用时（通常通过一个称为 trap 的特殊硬件指令），硬件将控制转移到预先指定的 trap 处理程序（即预先设置的操作系统），并同时将特权级别提升至内核模式。

在内核模式下，操作系统可以完全访问系统的硬件，因此可以执行诸如发起 IO 请求或为程序提供更多内存等功能。当操作系统完成请求的服务时，它通过特殊的 trap 返回指令，将控制权交还给用户。该指令（return-from-trap）返回到用户模式，同时将控制权交还给应用程序，回到应用离开的地方。

# 第一部分：虚拟化

### 1. 进程

进程——操作系统提供的基本抽象。进程的非正式定义言简意赅：进程就是运行中的程序。

进程可以处于以下 3 种状态之一：

- 运行：在 CPU 上运行，执行指令
- 就绪：已准备好运行，但未分配 CPU 时间片
- 阻塞：等待发生其他事件才会准备运行（就绪）

### 2. 如何提供有许多 CPU 的假象？

操作系统通过虚拟化 CPU 来提供这种假象。

通过让一个进程只运行一个时间片，然后切换到其他进程，即所谓的时分共享 CPU 技术。潜在的开销就是性能损失，因为每个进程的运行就会慢一点。

### 3. 机制和策略

机制：一些低级方法或协议，实现了所需的功能。例如上下文切换，它让操作系统能够停止运行一个程序，并开始在给定的 CPU 上运行另外一个程序。

策略：在这些机制之上，策略是在操作系统内做出某种决定的算法。例如给定一组可能的程序要在 CPU 上运行，操作系统如何抉择？操作系统的调度策略会做这样的决定。

### 4. 机制：受限直接执行

在保持控制权的同时，获得高性能，是构建操作系统的主要挑战之一。

硬件通过提供不同的执行模式来协助操作系统：用户模式和内核模式。

要执行系统调用，程序必须执行特殊的陷阱（trap）指令。问题是，陷阱如何知道在 OS 内执行哪些代码？

内核通过在启动时设置陷阱表来实现。内核必须谨慎地控制在陷阱上执行的代码。

操作系统做的第一件事，就是告诉硬件在发生某些异常事件时要运行哪些代码。

### 5. 进程切换时，操作系统如何重获 CPU 的控制权？

（1）协作方式：等待系统调用。大多数进程通过系统调用，将 CPU 的控制权转移给操作系统。如果应用程序执行了某些非法操作，也会将控制转移给操作系统。

（2）非协作方式：操作系统进行控制。需要硬件参与：时钟中断。启动时，操作系统必须启动时间，也必须通知硬件哪些代码在发生时钟中断时运行。

### 6. 上下文切换

操作系统为当前执行的进程保留一些寄存器的值（例如，保存到内核栈），并为即将执行的进程恢复一些寄存器的值（从内核栈读取）。

上下文切换的成本不仅仅来自寄存器的保存与恢复，程序运行时在 CPU 高速缓存，TLB，分支预测器和其他硬件中建立了大量的状态，切换时会导致状态的刷新，这可能导致显著的性能成本。

### 7. 进程调度

调度指标：周转时间=完成时间-到达时间。

调度策略：

（1）先进先出（FIFO）。可能带来护航效应，即一些耗时较少的潜在资源消费者，被排在重量级的资源消费者之后，导致周转时间变长。

（2）最短任务优先（SJF）。先运行最短的任务，然后是次短的任务，如此下去。也可能有护航问题。

（3）最短完成时间优先（STCF），或抢占式最短作业优先（PSJF）。几乎所有现代化的调度程序都是抢占式的。向 SJF 添加抢占，可以解决护航问题。

调度指标：响应时间=首次运行-到达时间。

调度策略：

（1）轮转（RR）。RR 在一个时间片内运行一个任务，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。RR 反复执行，直到所有任务都完成。系统设计者需要权衡时间片的长度，以便摊销上下文切换的成本，而又不会使系统不及时响应。

在周转时间与响应时间之间需要做权衡。第一种类型（SJF，STCF）优化周转时间，但对响应时间不利；第二种类型（RR）优化响应时间，但对周转时间不利。

### 8. 调度：多级反馈队列

多级反馈队列（MLFQ）需要解决 2 方面的问题：首先，优化周转时间；其次，降低响应时间。

多级反馈队列是用历史经验预测未来的典型例子，在操作系统中，使用此技术的有很多，比如硬件的分支预测及缓存算法。

多级反馈队列，它有多级队列，并利用反馈信息决定某个任务的优先级。以史为鉴：关注进程的一贯表现，然后区别对待。

MLFQ 的规则如下：

（1）先后规则：如果 A 的优先级> B 的优先级，运行 A（不运行 B）
（2）轮转规则：如果 A 的优先级=B 的优先级，轮转运行 A 和 B
（3）初始最高规则：任务进入系统时，放在最高优先级（最上层队列）
（4）用完下降规则：一旦任务用完其在某一层中的时间配额（不管中间主动放弃了多少次 CPU），就降低其优先级（移入低一级队列）
（5）不断重置规则：经过一段时间 S，就将系统中所有任务重新加入最高优先级队列

S 的值如何设置？如果 S 设置得太高，长任务会饥饿；如果设置得太低，交互型任务又得不到合适的 CPU 时间比例。

MLFQ 不需要对任务的运行方式有先验知识，而是通过观察工作的运行来给出对应的优先级。通过这种方式，使得短时间的任务能获得类似 SJF 的很好的全局性能，同时对长时间运行的 CPU 密集型负载也可以稳步推进。

### 9. 调度：比例份额

比例份额调度程序，也称为公平份额调度程序，调度程序的最终目标，是确保每个任务获得一定比例的 CPU 时间，而不是优化周转时间与响应时间。

比例份额有一个非常优秀的现代例子：彩票调度。越是应该频繁运行的进程，越是应该拥有更多地赢得彩票的机会。

彩票调度最精彩的地方在于利用了随机性。随机方法相对于传统的决策方式，至少有 3 点优势：

（1）避免奇怪的边界情况
（2）轻量，几乎不需记录任何状态
（3）很快

彩票调度中最不可思议的，或许就是实现简单。只需要一个不错的随机数生成器来选择中奖彩票和一个记录系统中所有进程的数据结构（一个列表），以及所有彩票的总数。

比如有 3 个任务 ABC，彩票总数为 60，它们获得的彩票数分别为：A-10，B-20，C-30。现使用链表将 ABC 排列如下：A-B-C（C-B-A 等都可以），表示 A 的区间为[1，10]，B 的区间为[11，30]，C 的区间为[31，60]。然后获取一个在 1~60 的随机数，比如 34，则 C 被调度（因为刚好落在 C 的区间段）。

如何为任务分配彩票？这是一个棘手的问题，没有最佳答案。

虽然随机方式可以使得调度程序的实现简单（且大致正确），但偶尔并不能产生正确的比例。步长调度解决了这个问题，它是一个确定性的公平分配方案。

步长调度也很简单。系统中每个人物都有自己的步长，这个值与票数值成反比。每次进程运行后，让它的计数器增加它的步长，记录总体的进展。之后，调度程序使用进程的步长及行程值来确定调度哪个进程。当需要进行调度时，选择目前拥有最小行程值的进程，并且在运行之后，将该进程的行程值增加一个步长。

比如以 60 为标准，前文 ABC 的步长分别为 A-6，B-3，C-2。因为刚开始调度时，ABC 的行程都是 0，随机选一个执行，比如 A，则 A 的行程为 6。之后 BC 中也随机选一个，比如选 B 执行，则 B 的行程为 3。之后肯定是 C 会执行，C 的行程为 2。此时，因为 C 的行程最短，则 C 会被再次执行。

在彩票调度中，票数值越高，理论上越容易被选中（基于大数定律，概率趋于期望。但有例外，因为是随机性的）。而在步长调度中，票数值越高，步长越短，越容易被执行（小步快跑）。

彩票调度只能运行一段时间后，在概率上实现比例，而步长调度可以在每个调度周期后做到完全正确。既然如此，为什么还需要彩票调度？因为彩票调度有一个步长调度没有的优势：不需要全局状态。因此，彩票调度算法能够更合理地处理新加入的进程。

比例份额调度中，彩票调度通过随机值，聪明地做到了按比例分配。步长调度能够确定的获得需要的比例。但是，它们并没有作为 CPU 调度程序被广泛使用。一个原因是这两种方案都不能很好地适合 IO，另一个原因是其中最难的票数分配问题并没有确定的解决方案。

即使如此，在容易确定份额比例的场景（比如，在虚拟数据中心中，分配 1/4 的 CPU 周期给 Windows 系统，其他的给 Linux 系统），比例份额调度还能发挥优势：简单高效。

### 10. 多处理器调度

多处理器与单 CPU 的基本区别：区别的核心在于对硬件缓存的使用，以及多处理之间共享数据的方式。

（1）单队列多处理器调度（SQMS）。将所有需要调度的任务放在一个单独的队列中，然后按照 CPU 个数选择合适的任务来运行。

优势：简单，直接复用之前单 CPU 的调度方式。负载均衡好。

劣势：其一，缺乏可扩展性。多处理器环境下，需要加锁来保证正确性。而锁的使用非常耗时。其二，缺乏缓存亲和性。任务会在不同的处理器中执行，难以利用缓存的优势。

（2）多队列多处理器调度（MQMS）。基本调度框架包含多个调度队列，每个队列可以使用不同的调度策略。

优势：天生具有可扩展性。队列的数量会随着 CPU 的增加而增加，因此锁和缓存的争用都不是大问题。具有良好的缓存亲和度。

劣势：负载不均。如何解决？通过任务的跨 CPU 迁移，可以真正的实现负载均衡。系统如何发起这样的迁移？使用工作窃取（work stealing）技术。工作量较少的队列不定期地从其他较多的队列中“窃取”一个或多个工作，实现负载均衡。不定期到底是多长？找到合适的阈值仍然是黑魔法，这在系统策略设计中很常见。

（3）Linux 多处理器调度

在构建多处理器调度程序方面，Linux 社区一致没有达成共识。一直以来，存在 3 种不同的调度程序：

- O(1)调度程序，采用多队列，基于优先级的（类似 MLFQ），随着时间的推移改变进程的优先级，然后调度最高优先级进程，来实现调度目标。交互性得到了特别关注。
- 完全公平调度程序（CFS），采用多队列，基于确定的比例调度（类似步长调度）。
- BF 调度程序（BFS），采用单队列，基于比例调度，但采用更加复杂的方案，称为最早最合适虚拟截止时间优先算法（EEVEF）。

### 11. 虚拟内存的目标

地址空间，是操作系统提供的易用的物理内存抽象。

（1）透明：操作系统提供的假象不应该被应用程序看破，程序不应该感知到内存被虚拟化的事实。相反，程序的行为就好像它拥有自己的私有物理内存。

（2）效率：包括时间上（不会使程序运行得更慢）和空间上（不需要太多额外的内存来支持虚拟化）。在实现高效率虚拟化时，操作系统不得不依靠硬件支持，包括 TLB 这样的硬件功能。

（3）保护：操作系统应该确保进程受到保护，不会受其他进程影响，操作系统本身也不会受进程影响。保护在进程之间提供隔离的特性。

### 12. 内存泄漏

如果忘记释放内存，就会发生内存泄漏。

在长时间运行的应用程序或系统中，内存泄漏是一个巨大的问题。因为缓慢泄漏的内存会导致内存不足，此时需要重新启动。

一般来说，当你用完一段内存时，应当确保释放它。请注意，使用垃圾收集语言在这里没有什么帮助：如果你仍然持有某块内存的引用，那么垃圾收集器就不会释放它。

内存泄漏的根源在于人。

### 13. 机制：地址转换

基于硬件的地址转换，硬件对每次内存访问进行处理，将指令中的虚拟地址转换为数据实际存储的物理地址。

当然，仅仅依靠硬件不足以实现虚拟内存，操作系统必须在关键的位置介入，设置好硬件，以便完成正确的地址转换。

动态（基于硬件）重定位：具体来说，每个 CPU 需要 2 个硬件寄存器，基址寄存器和界限寄存器。进程中使用的内存引用都是虚拟地址，硬件接下来将虚拟机地址加上基址寄存器中的内容，得到物理地址，再发给内存系统。

有时候我们将 CPU 的这个负责地址转换的部分，称为内存管理单元（MMU）。

操作系统需要介入的关键时刻：
（1）内存管理：
需要为新进程分配内存；
从终止的进程回收内存；
一般通过空闲列表来管理内存；
（2）基址/界限管理
必须在上下文切换时，正确设置基址/界限寄存器；
（3）异常处理
当异常发生时执行的代码，可能的动作是终止犯错的进程；

通过虚拟化，操作系统（在硬件的帮助下）将丑陋的机器现实转化成一种有用的、强大的、易于使用的抽象。

### 14. 分段

内部碎片：已经分配的内存单元内部有未使用的空间（即碎片），造成了浪费。

简单的通过基址/界限寄存器实现的虚拟内存很浪费，因为栈和堆之前的空间并没有被进程使用，却依然占用了实际的物理内存。

为了解决这个问题，分段的概念应运而生。这个想法很简单：在 MMU 中引入不止一个基址/界限集群器对，而是给地址空间内的每个逻辑段一对。

一个段只是地址空间里的一个连续定长的区域，在典型的地址空间里有 3 个逻辑不同的段：代码、栈和堆。

系统运行时，地址空间中不同的段被重定位到物理内存中。与之前的整个地址空间只有一个基址/界限寄存器对的方式相比，节省了大量的物理内存（按需细粒度划分，消除碎片）。

外部碎片：空闲空间被分割成不同大小的小块，成为碎片，后续的请求可能失败，因为没有一块足够大的连续空闲空间，即使这时总的空闲空间超出请求的大小。

然而，分段也带来了新的问题：外部碎片（每个进程都有一些段，段的大小不同。物理内存很快充满了许多空闲空间的小洞，因为很难分配给新的段，或扩大已有的段）。例如：一个进程需要分配一个 20KB 的段，当前有 24KB 的空闲，但并不连续（是不相邻的块）。因此，操作系统无法满足这 20 KB 的请求。

如何解决？

（1）紧凑物理内存，重新安排原有的段（类似 java 内存回收的复制算法）。

（2）一种更简单的做法是利用空闲列表管理算法，试图保留大的内存块用于分配。

### 15. 空闲空间管理

大多数分配程序采用的通用机制：
（1）分割与合并
（2）追踪已分配空间的大小
（3）嵌入空闲列表
（4）让堆增长

基本策略：
（1）最优匹配：遍历整个空闲列表，找到最接近请求大小的空闲块，尽量避免空间浪费（较高的性能代价）
（2）最差匹配：找到最大的空闲块，分配之后，将剩余的加入空闲列表（过量的碎片，很高的开销）
（3）首次匹配：找到第一个足够大的块，分配之后，将剩余的加入空闲列表（可能列表开头有很多小块）
（4）下次匹配：维护一个指针，指向上一次查找结束的位置（解决开头小块的问题）
（5）分离空闲列表（例如 SLAB，厚块分配程序）：分开管理。如果某个应用程序经常申请一种或几种大小的内存空间，那就用一个独立的列表，单独管理。其他大小的请求都交给更通用的内存分配程序
（6）伙伴系统（例如二分伙伴分配程序）：空闲空间从概念上被看成大小为 2^N 的大空间，当有一个内存分配请求时，空闲空间被递归地一分为二，直到刚好适配请求的大小（漂亮之处在于，块被释放时，很容易合并）

这些方法都有一个重要的问题：缺乏可扩展性。具体来说，就是查找列表会很慢。

因此，更先进的分配程序采用更复杂的数据结构来优化这个开销，牺牲简单性来换取性能。例子包括平衡二叉树、伸展树和偏序树等。

提示：如果有一千个解决方案，就没有特别好的

存在如此多的不同的算法来尝试减少外部碎片，正说明了解决这个问题没有最好的办法。因此我们满足于找到一个合理的足够好的方案。

唯一真正的解决方案就是，完全避免这个问题：永远不要分配不同大小的内存块。

### 16. 分页

操作系统有 2 种方法，来解决大多数空间管理的问题。

第一种是将空间分割成不同长度的分片，就像虚拟内存管理中的分段。然而空间本身会碎片化；

第二种是分页：将空间分割成固定长度的分片。

为了记录地址空间的每个虚拟页放在物理内存中的位置，操作系统通常为每个进程保存一个数据结构，即页表（存储虚拟-物理地址转换）。

分页有许多优点：

首先，分页不会导致外部碎片，因为分页将内存划分为固定大小的单元。
其次，分页非常灵活，支持稀疏虚拟地址空间。

然而，实现分页支持而不小心考虑，会导致系统变慢（有许多额外的内存访问来访问页表）和内存浪费（内存被页表塞满，而不是有用的数据）

### 17. 快速地址转换（TLB）

使用分页作为核心机制来实现虚拟内存，可能会带来较高的性能开销，因为需要访问页表将虚拟地址映射为物理地址。

如何加速地址转换？

我们需要增加所谓的地址转换旁路缓冲存储器（Translation-Lookaside Buffer，TLB），即频繁发生的虚拟到物理地址转换的硬件缓存（更好的名字应该是地址转换缓存）。对于每次内存访问，硬件先检查 TLB，看是否命中（有期望的转换映射），如果命中，就完成转换（很快），不用访问页表。

类似其他缓存，TLB 的成功依赖于空间和时间局部性。

谁来处理 TLB 未命中？可能有 2 个答案：硬件或软件（操作系统）

TLB 不能满足所有程序的需求，例如：上下文切换时需要对 TLB 进行处理。一个程序短时间内访问的页超过 TLB 的页数，就会产生大量未命中，运行速度就会变慢（超出 TLB 覆盖范围，一种解决方案是：支持更大的页）

### 18. 分页：较小的表

页表太大，因此消耗的内存太多。如何让页表更小？

简单的解决方案：更大的页。大页在数据库管理系统和其他高端商业应用程序中很常见。然而，大内存页会导致每页内的浪费，即内部碎片问题（因为浪费在分配单元内部）。因此，大多数系统在常见的情况下使用相对较小的页（4KB 或 8KB）。问题不会如此简单的解决。

混合方法：分页和分段。每当有 2 种合理但不同的方法时，你应该研究两者的结合，看能否两全其美（这种组合成为杂合，杂交混合）。我们杂合的方法是，不是为进程的整个地址空间提供单个页表，而是为每个逻辑分段提供一个（相对整个地址空间来说，段的空间显然很小，页表当然也小了）。但是，这种方案仍有问题：分段有外部碎片的可能。

多级页表：将线性页表变成类似树的东西。首先，将页表分成页大小的单元（页表项）。然后，对这些页表项建立页目录。页目录指向页表的各个部分，不要求页表是连续的了。多级表是一个时间-空间折中的例子（如果你希望更快地访问特定的数据结构，就必须为该结构付出空间的代价）。

多级页表的优势：
（1）紧凑，支持稀疏的地址空间。
（2）更容易管理内存
劣势：
（1）TLB 未命中时，需要加载 2 次（一次页目录，一次页表项），线性页表只需要 1 次
（2）为了节省宝贵的内存，页表查找更加复杂（通常我们愿意增加复杂性以提高性能或降低管理费用）

反向页表：页表世界中更极端的空间节省。只保留了一个页表，其中的项代表系统的每个物理页，而不是有许多页表（系统的每个进程都有一个）。页表项告诉我们哪个进程在使用此页，以及该进程的哪个虚拟页映射到此物理页（一般使用哈希表加速查找）。

当页表太大而无法一次性装入物理内存时，可以将页表中的一部分交换到磁盘。

### 19. 机制：交换空间

为什么我们要为进程支持巨大的地址空间？答案还是方便和易用性。

我们要做的第一件事情，就是在硬盘上开辟一部分空间用于物理页的移入和移出。在操作系统中，一般这样的空间称为交换空间。

如果希望允许页交换到硬盘，必须添加更多的机制。当硬件在页表项中查找时，可能发现页不在物理内存中。硬件可通过页表项的存在位判断。存在位为零，说明页不在内存中，而在磁盘上。

访问不在物理内存中的页时，会发生页错误（实际上，它应该被称为页未命中），操作系统被唤起来处理，一段称为“页错误处理程序”的代码会被执行。

当内存快满时，操作系统可能希望先交换出一个或多个页，以便为即将交换入的新页留出空间。选择哪些页被替换的过程，被称为页交换策略。

### 20. 替换策略

最优替换策略：理想中的，用作比较基准。

简单策略：FIFO。一般来说，当缓存变大时，缓存命中率是会提高的（变好）。但是采用 FIFO 策略，命中率可能反而下降（即 Belady 的异常）。

另一个简单策略：随机。随机取决于当时的运气。

利用历史数据：最不经常使用（LFU）：页替换策略可以使用的一个历史信息是频率。最近最少使用（LRU）：页更常用的属性是访问的近期性，越近被访问的过的页，也许再次访问的可能性也就越大。这些都是基于局部性原则。

由于实现完美的 LRU 代价非常昂贵，我们否实现一个近似的 LRU 算法，并且依然能够获得预期的效果？

答案是肯定的：从计算开销的角度来看，近似 LRU 更为可行。这个想法需要硬件增加一个使用位（有时称为引用位，用来记录历史使用信息）。有一个简单的方法称为时钟算法，周期性地检查使用位，替换使用位为 0 的页（表示最近未使用）。如果都被使用，则将所有页都置为 0。实际上，任何周期性地清除使用位，然后通过区分使用位是 1 和 0 来判定应该替换哪个页的方法都是可以的。

由于分页到硬盘非常昂贵，因此频繁分页的成本太高。所以，过度分页的最佳解决方案往往很简单：购买更多的内存！

# 第二部分：并发

### 21. 为什么操作系统要研究并发？

Dijkstra 提出的一些关键并发术语：

临界区（critical section）：是访问共享资源的一段代码，资源通常是一个变量或数据结构。

竞态条件（race condition）：出现在多个执行线程大致同时进入临界区时，它们都试图更新共享的数据结构，导致了令人惊讶（也许是不希望的）的结果。

不确定性（indeterminate）：程序由一个多个竞态条件组成，程序的输出因运行而异，具体取决于哪些线程在何时运行。这导致结果是不确定的，而我们通常期望计算机系统给出确定的结果。

互斥（mutual exclusion）：为了避免这些问题，线程应该使用某种互斥原语。这样做可以保证只有一个线程进入临界区，从而避免出现竞态，并产生确定的程序输出。

要想达到原子性，要求硬件提供一些有用的指令，可以在这些指令上构建一个通用的集合，即所谓的同步原语（synchronization primitive）。

我们将使用同步原语，将指令的短序列变成原子性的执行块（全部或没有）。

操作系统本身就是第一个并发程序。毫不奇怪，页表、进程列表、文件系统结构以及几乎每个内核数据结构都必须小心地访问，并使用正确的同步原语才能正常工作。

除了访问共享变量需要为临界区提供原子性之外，还有一种常见的交互，即一个线程在继续执行之前必须等待另一个线程完成某些操作。因此，接下来，我们不仅要研究如何构建对同步原语的支持来支持原子性，还要研究支持在多线程程序中常见的睡眠/唤醒交互的机制。

### 22. 锁

锁变量（简称锁）保存了锁在某一时刻的状态。

锁为程序员提供了最小程度的调度控制。

通过给临界区加锁，可以保证临界区内只有一个线程活跃。锁将原本由操作系统调度的混乱状态变得更为可控。

如何实现锁？

第一，锁必须提供互斥（安全性）。最基本的，锁是否有效，能够阻止多个线程进入临界区。

第二，锁应该保证公平性（活性）。出现竞争时，应该无饥饿（总是能获得锁）。

第三，锁的性能应该足够好（活性）。

锁需要硬件支持和操作系统支持。

### 23. 条件变量

锁之外的另一个重要的同步原语：条件变量。

线程可以使用条件变量（condition variable），来等待一个条件变为真。条件变量是一个显式队列，当某些执行状态（即条件，condition）不满足时，线程可以把自己加入队列，等待（waiting）该条件。另外某个线程，当它改变上述状态时，就可以唤醒一个或者多个等待线程（通过在该条件上发信号），让它们继续执行。

Dijkstra 最早在“私有信号量”中提出这种思想。Hoare 后来在关于 Monitor 的工作中，将类似的思想称为条件变量。

使用条件变量发信号时，总是持有锁（hold the lock when calling signal）。

调用 wait 时持有锁，因为 wait 调用总是假设你调用它时已经持有锁，调用者睡眠之前会释放锁以及返回前重新持有锁。

总之，一般化形式是正确的：调用 signal 和 wait 时要持有锁，这样保证了安全性。

### 24. 信号量

事实上，Dijkstra 及其同事发明了信号量（semaphore），作为与同步有关的所有工作的唯一原语。

可以使用信号量作为锁和条件变量。也可以使用锁和条件变量来实现信号量（想一想，为什么这些同步原语能够互相实现？）。

信号量是有一个整数值（即令牌数目）的对象，可以用两个函数来操作它。在 POSIX 标准中，是 sem_wait() 和 sem_post()。即 PV 原语（历史上，Dijkstra 使用荷兰语，将 sem_wait 称为 P，即荷兰语单词"to probe"，将 sem_post 称为 V，即荷兰语单词 "to test"）。

P 操作会使信号量减一。线程调用 P 操作，要么立即返回（信号量的值大于等于 1），要么会让调用者挂起（睡眠），直到被 V 操作唤醒。

V 操作会使信号量增一。线程调用 V 操作，如果有等待线程，唤醒其中一个。

当信号量为负数时，这个值就是等待线程的个数。

二值信号量（即初始值为 1）就是锁。

信号量是编写并发程序的强大而灵活的原语。有程序员会因为简单实用，只用信号量，不用锁和条件变量。

### 25. 常见并发问题

第一类，非死锁缺陷：违反原子性缺陷和违反顺序缺陷。

违反原子性（即应该一起执行的指令序列并没有一起执行）：违反了多次内存访问中预期的可串行性（即代码本意是原子的，但在执行过程中并没有强制实现原子性）。

违反顺序（即两个线程所需的顺序没有强制保证）：两个内存访问的预期顺序被打破了（即 A 应该在 B 之前执行，但是实际运行过程中却不是这个顺序）。

大部分（97%）的非死锁问题是违反原子性和违反顺序这两种。

第二类，死锁缺陷。

死锁产生的 4 个条件：

- 互斥：使用无锁（和无等待）的数据结构（通过强大的硬件指令，构造出不需要锁的数据结构）来避免使用锁。
- 持有并等待：通过原子地抢锁来避免。
- 非抢占：例如 trylock() 函数尝试获得锁，如果失败则重试。可能引入活锁问题，但可以通过随机等待来避免。
- 循环等待：获取锁时，提供一个全序或者偏序，即可避免。

除了这些死锁预防，某些场景更适合死锁避免。比如使用银行家算法来分配资源。

鸵鸟算法：还有一种常用的策略就是允许死锁偶尔发生，检查到死锁时再采取行动（即重启大法）。

### 26. 基于事件的并发

除了使用线程来实现并发外，一些基于图形用户界面（GUI）的应用，或某些类型的网络服务器（node.js），常常采用另一种并发方式，即基于事件的并发。

基于事件的并发针对线程并发的 2 方面的问题：一是在多线程应用中，正确处理并发很有难度（比如死锁等）。二是开发者无法控制多线程在某一时刻的调度（程序员只是创建了线程，如何调度，还是依赖于操作系统）。

问题：不用线程，如何构建并发服务器？

基本想法：事件循环。我们等待事件发生，当事件发生时，检查事件类型，然后做少量的相应动作（可能是 IO 请求，或者调度其他事件准备后续处理）。

简单性：使用单个 CPU 和基于事件的应用程序，因为一次只处理一个事件，所以不需要获取和释放锁。并发程序中发现的问题不复存在。

但是，如果发生阻塞调用，整个服务器就会阻塞，直到调用完成。因此，我们在基于事件的系统中必须遵守一条规则：不允许阻塞调用。

通常阻塞调用的主犯是某种 IO，为了克服这个限制，许多现代操作系统引入了异步 IO 来解决。

注意：在没有异步 IO 的系统中，纯基于事件的方法无法实现（线程和事件混合可以解决，例如使用线程池来管理未完成的 IO）。

基于事件的方法的另一个问题是：当事件处理程序发出异步 IO 时，它必须保存一些程序状态，以便下一个事件处理程序在 IO 最终完成时使用。这个额外的工作在基于线程的程序中是不需要的（因为程序需要的状态在线程栈中）。

这种保存状态的操作，叫作手工栈管理，这是基于事件编程的基础。

基于事件的方法还有其他一些困难。

例如，当系统从单 CPU 转向多 CPU 时，基于实践的方法的一些简单性就消失了。具体来说，为了利用多个 CPU，事件服务器必须并行运行多个事件处理程序。发生这种情况时，就会出现常见的同步问题。因此，在现代多核系统上，无锁的简单事件处理已不再可能。

另一个问题是，基于事件的方法，不能很好地与某些类型的系统活动集成，例如分页（由于页错误导致的隐式的阻塞很难避免，因此频繁发生时可能导致较大的性能问题）。

还有就是随着时间的推移，基于事件的代码可能很难管理，因为各种函数的确切语义发生了变化。

基于事件的服务器为应用程序本身提供了调度控制，但是这样做的代价是复杂性以及现代系统的其他方面（例如分页）的集成难度。由于这些挑战，没有哪一种方法表现最好。因此，线程和事件在未来很多年内可能会持续作为解决同一并发问题的两种不同方法。

# 第三部分：持久性

### 27. 系统架构

典型系统架构：

- CPU 通过某种内存总线（专有的）或互连电缆连接到系统内存
- 图像或其他高性能 IO 设备通过通用 IO 总线（例如 PCI）连接到系统
- 最后是外设总线（如 SCSI、SATA、USB）将最慢的设备（磁盘、鼠标等）连接到系统

为什么要这样的分层架构？简单回答：因为物理布局以及造价成本。

越快的总线越短，因此高性能的内存总线没有足够的空间连接太多设备。另外，在工程上，高性能的总线造价高。因此，将要求高性能的设备（比如显卡）离 CPU 更近一些，低性能的设备离 CPU 远一些。

### 28. 标准设备

包括 2 部分。

第一部分是向系统其他部分展现的硬件接口。一个简化的设备接口包括 3 个寄存器：

一个状态寄存器，可读取并查看设备的当前状态；

一个命令寄存器，用于通知设备执行某个具体任务；

一个数据寄存器，将数据传给设备或从设备接收数据；

通过读写这些寄存器，操作系统可以控制设备的行为。

第二部分是它的内部结构。这部分包含设备相关的特定实现，负责具体实现设备展示给系统的抽象接口。

非常简单的设备通常用一个或几个芯片来实现它们的功能。更复杂的设备会包含简单的 CPU、一些通用内存、设备相关的特定芯片。

### 29. 标准协议

操作系统与设备交互，以便让设备做事。协议如下：

第一步，轮询设备，操作系统通过反复读写状态寄存器，等待设备进入可用接收命令的就绪状态；

第二步，操作系统下发数据到数据寄存器；

第三步，操作系统将命令写入命令寄存器，这样设备就知道数据已经准备好了，它该开始执行命令了；

第四步，操作系统再次轮询设备，等待并判断设备是否执行完成命令。

轮询过程比较低效，在等待设备执行完成命令时浪费大量的 CPU 时间，可通过中断来减少 CPU 开销（中断处理程序是一小段操作系统代码，它会结束之前的请求，并唤醒等待 IO 的进程继续执行）。

注意：使用中断并非总是最佳方案。

如果设备非常快，那么最好的办法就是轮询。如果设备慢，那么允许发生重叠的中断更好。如果设备的速度未知，可以考虑使用杂合策略：先尝试轮询一小段时间，如果设备没有完成，则再使用中断。

另一个不要使用中断的场景是网络。网络端收到大量的数据包，如果每个包都发生一次中断，那么有可能导致操作系统发生活锁。

基于中断的优化，可以使用合并：将多次中断合并为一次中断，从而降低处理中断的代价。

利用 DMA（Direct Memory Access）进行高效的数据传送。DMA 引擎是系统中的一个特殊设备，可以协调完成内存和设备间的数据传送，不需要 CPU 的介入。

中断、DMA 及相关思想，都是在快速 CPU 和慢速设备之间权衡的结果。

### 30. 如何与设备通信？

随着技术的不断发展，主要有 2 种方式实现与设备的交互。

第一种是使用明确的 IO 指令。这些指令规定了操作系统将数据发送到特定设备寄存器的方法，从而允许构造标准协议。

这些指令通常是特权指令，因为操作系统是唯一可以直接与设备交互的实体。

第二种方法是内存映射 IO。通过这种方式，硬件将设备寄存器作为内存地址提供。

当需要访问设备寄存器时，操作系统装载或者存入（读写）到该内存地址；然后硬件会将装载/存入转移到设备上，而不是物理内存。

两种方法没有一种具备极大的优势，两种方法今天都在使用。

每个设备都有非常具体的接口，如何将它们纳入操作系统？

这个问题可以通过古老的抽象技术来解决。在最底层，操作系统的一部分软件清楚地知道设备如何工作，我们将这部分软件称为设备驱动程序，所有设备交互的细节都封装在其中。

因为所有需要插入系统的设备都需要安装对应的驱动程序，所以久而久之，驱动程序的代码在整个内核代码中的占比越来越大。

如果有人跟你说操作系统包含上百万行代码，实际的意思是包含上百万行驱动程序代码。

因为驱动程序的开发者大部分是业余的（不是全职内核开发者），所以他们更容易写出 BUG，因此是内核崩溃的主要贡献者（这锅甩了）。

### 31. 磁盘调度

题外话：这里针对的是磁盘（机械式），而不是固态硬盘（电子式）。目前虽然固态硬盘越来越常见，但是磁盘由于其高性价比（容量大，价格低，没有读写次数限制等），在存储器领域仍然很活跃，以下的讨论依旧有现实意义。

由于 IO 的高成本，操作系统在决定发送给磁盘的 IO 顺序至关重要。具体来说，给定一组 IO 请求，磁盘调度程序检查请求，并决定下一个要调度的请求。

与任务调度不同（每个任务的执行时间通常是不知道的），磁盘调度通过估计请求的寻道和可能的旋转延迟，可以知道每个请求将花费多长时间。因此，磁盘调度程序将遵循最短任务优先原则（Shortest-Job-First），贪婪地选择先服务花费时间最少的请求。

（1）SSTF（Shortest-Seek-Time-First）：最短寻道时间优先

SSTF 按磁道对 IO 请求队列排序，选择在最近磁道上的请求先完成。

但是，SSTF 不是万能的。有 2 个问题：

一是操作系统无法利用磁盘驱动器的几何结构，而是只会看到一系列的块。这个问题，操作系统可以实现最近块优先（NBF），而不是 SSTF，然后用最近的块地址来调度请求。

二是饥饿问题：磁头当前所在位置的磁道请求总是优于其他，导致其他远离磁头的磁道请求迟迟不能得到响应。

（2）SCAN：电梯算法

SCAN 简单地已跨越磁道的顺序来服务磁盘请求（即扫描），以此来避免饥饿问题。

扫描的方向有多种（导致电梯算法有多个变种），可以按照同一个方向循环扫描，或者像电梯一样，从头至尾，然后从尾至头，循环往复。

然而，SCAN 及其变种并不是最好的调度技术。特别是 SCAN（甚至是 SSTF）实际上并没有严格遵守 SJF 原则。具体来说，它们忽视了旋转延迟。

（3）SPTF（Shortest-Positioning-Time-First）：最短定位时间优先

定位需要比较旋转和寻道的相对时间，它基于整体耗时考虑。如果寻道时间远远高于旋转延迟，那么 SSTF（和变体）就很好。当寻道和旋转的时间大致相当时，SPTF 是有用的，它提高了性能。

然而，SPTF 在操作系统中实现起来非常困难。操作系统通常不太清楚磁道边界在哪，也不知道磁头当前的位置（旋转到哪了）。因此，SPTF 通常在驱动器内部执行。

在现代系统中，磁盘可以接受多个分离的请求。操作系统调度程序通常会选择它认为最好的几个请求（IO 合并），将它们全部发送到磁盘。磁盘然后利用磁头位置和详细的磁道布局信息等内部知识，以最佳可能顺序（SPTF）服务与这些请求。

### 32. RAID

廉价磁冗余磁盘阵列（Redundant Array of Inexpensive Disks，PS：也有将 I 认为是独立（Independent）），与单个磁盘相比，RAID 有 3 大优势：

- 性能好：并行使用多个磁盘可以加快 IO 时间
- 容量大：组合多个磁盘供使用
- 可靠性高：通过不同形式的冗余，容许某些故障

RAID 将大量独立磁盘扩充成更大、更可靠的单一实体，对外是透明的（上面的硬件和软件对这种变化相对不在意）。

（1）RAID 0：条带
（1）RAID 1：镜像
（2）RAID 2：海明码校验
（3）RAID 3：奇偶位校验
（4）RAID 4：专用奇偶块校验，磁盘条带化
（5）RAID 5：条带奇偶块校验，磁盘条带化
（6）RAID 6：行列条带奇偶块校验，磁盘条带化

RAID 比较：容量、可靠性和性能

|        | RAID 0 |  RAID 1 | RAID 4  | RAID 5  |
| ------ | :----: | ------: | ------- | ------- |
| 容量   |   N    |     N/2 | N-1     | N-1     |
| 可靠性 |   0    |   1~N/2 | ?       | ?       |
| 顺序读 |  N·S   | (N/2)·S | (N-1)·S | (N-1)·S |
| 顺序写 |  N·S   | (N/2)·S | (N-1)·S | (N-1)·S |
| 随机读 |  N·R   |     N·R | (N-1)·R | N·R     |
| 随机写 |  N·R   | (N/2)·R | (1/2)·R | (N/4)·R |
| 读延迟 |   T    |       T | T       | T       |
| 写延迟 |   T    |       T | 2·T     | 2·T     |

说明：

N 表示 N 块磁盘。容量这一行， 因为镜像有冗余，故可用的容量为 N/2。

S 表示顺序操作时的性能。顺序读这一行，因为镜像有冗余，顺序读取同一个数据，其实镜像间不能并行，最多有 N/2 顺序读可以并行，故为 (N/2)·S。

R 表示随机操作时的性能。随机读这一行，因为 RAID-5 采用的是条带化奇偶块检验，利用了全部磁盘；而 RAID-4 使用专用的奇偶块磁盘，可读取的磁盘数少了一个。随机写这一行，RAID-4 因为有专用的奇偶块磁盘，写入时不能并行（小写入问题），而且每个逻辑 IO 需要进行 2 次 IO（一次读取，一次写入），故性能为(1/2)·R。而 RAID-5 是条带化奇偶块检验，可以并行。4 倍损失是由于每个 RAID-5 写入需要操作 2 个磁盘，且每个磁盘需要进行 2 次 IO（与 RAID-4 一样），故性能为(N/4)·R。

T 表示一次操作（读/写）的延时。在写这一行，由于 RAID-4 与 RAID-5 每次对同一个磁盘需要进行 2 次 IO，故延迟为 2·T。

有很多可能的 RAID 级别可选，使用确切 RAID 级别在很大程度上取决于用户的优先级。

如果严格要求性能而不关系可靠性，那么条带显然是最好的。

如果想要随机 IO 的性能和可靠性，镜像是最好的，但是代价是容量下降。

如果容量和可靠性是主要目标，那么 RAID-5 胜出，但是代价是小写入的性能不行。

如果总是在按顺序执行 IO 操作，并希望最大化容量，那么 RAID-5 也是最有意义的。

### 33. 存储虚拟化

进程，它是虚拟化的 CPU；地址空间，它是虚拟化的内存。现在，我们加上虚拟化拼图中更关键的一块：持久存储。

随着时间的推移，存储虚拟化形成了 2 个关键的抽象。

第一个抽象是文件。文件就是一个线性字节数组，每个字节都可以读取和写入。由于历史原因，文件的低级名称通常称为 inode 号。

inode 是许多文件系统使用的通用名称，用于描述保存给定文件的元数据的结构，例如其长度、权限以及其组成块的位置。

第二个抽象是目录。一个目录，像一个文件一样，也有一个低级名字（即 inode 号），但是它的内容非常具体：包含 <用户可读名字，低级名字> 对的列表，将用户可读名称映射到低级名称。

目录中的每个条目都指向文件或其他目录。通过将目录放入其他目录中，用户可以构建任意的目录树（或目录层次结构），在该目录下存储所有文件和目录。

名称在系统中很重要，因为访问任何资源的第一步就是能够命名它。

只有当引用计数达到零时，文件系统才会释放 inode 和相关的数据块，从而真正删除该文件。

### 34. 文件系统的实现

这里介绍一个简单的文件系统的实现，称为 VSFS（Very Simple File System），它是典型 UNIX 文件系统的简化版本。

文件系统是纯软件。考虑文件系统时，通常需要考虑 2 个不同的方面:

第一个方面是文件系统的数据结构。换言之，文件系统在磁盘上使用哪些类型的结构来组织其他数据和元数据？

第二个方面是访问方法。如何将进程发出的调用，比如 open 、read、write 等映射到它的结构上？

我们需要做的第一件事，就是将磁盘分成块（block）。简单的文件系统只使用一种块大小，通常选择 4KB。

这些块中应该存储什么数据？

（1）数据区域：首先想到的应该是用户数据。我们将存储用户数据的磁盘区域称为数据区域。

（2）inode 表：文件系统必须记录每个文件的信息，该信息是元数据的关键部分。为了存储这些信息，文件系统通常有一个名为 inode 的结构。为了存放 inode，我们还需要在磁盘上预留一些空间。我们将这部分磁盘称为 inode 表。

（3）分配结构：目前为止，我们的文件系统有了数据块（D）和 inode（I），但还缺一些东西：需要某种方法来记录 inode 或数据块是空闲还是已分配。

可能有多种分配记录方法：

- 空闲列表。指向第一个空闲块，然后它又指向下一个空闲块，以此类推。

- 位图。每个位用于指示相应的对象/块是否空闲（0），还是正在使用（1）。

（4）超级块：还需考虑最后一部分：超级块（元数据的元数据）。超级块包含关于该特定文件系统的信息，包括：

- 文件系统中有多个个 inode 和数据块
- inode 表的开始位置
- 文件系统类型

等等。在挂载文件系统时，操作系统首先读取超级块，初始化各种参数，然后将该卷（不同的卷可能有不同的文件系统）添加到文件系统树中。当卷中的文件被访问时，系统就会知道在哪里查找所需的磁盘上的结构（通过 inode 表）。

文件系统最重要的磁盘结构之一就是 inode（UNIX 开发人员 Ken Thompson 给出的历史性名称），几乎所有的文件系统都有类似的结构。

每个 inode 都由一个数字隐式引用 inumber（即低级名称），在 VSFS 中，给定一个 inumber，应该能够直接计算磁盘上相应节点的位置。

设计 inode 时，最重要的决定之一就是如何引用数据块的位置。一种简单的方法是在 inode 中有一个或多个直接指针（磁盘地址），每个指针指向属于该文件的一个磁盘块。但是这种方式无法表示大文件。

为了支持更大的文件，文件系统引入了间接指针（指针的指针），它不是指向包含用户数据的块，而是指向包含更多指针的块，块中每个指针再指向用户数据。如果还不够，可以再增加一层索引（多级索引）。另一种方法是使用范围而不是指针。范围就是一个磁盘指针加一个长度（以块为单位）。

基于指针的方法最灵活，但是每个文件使用大量元数据。基于范围的方法不够灵活但是更加紧凑。

设计 inode 还有一个更加简单的方案，即使用链表。在 inode 中，只需一个指针，指向文件的第一个块。如果文件很大，则块的末尾再添加一个指针，指向下一个，直到满足。但是，链接式文件分配对于某些工作负载，表现不佳（一次只能读取一个块）。方案可以改进：在内存中保留链接信息表（所谓的文件分配表）。

你可能想知道确切的目录存储在哪里。通常，文件系统将目录视为特殊类型的文件。目录有一个 inode，位于 inode 表中的某处（与文件通过标识来区分）。该目录具有由 inode 指向的数据块（或间接块），这些数据块就存在于数据块区域中。

文件的读取：假设现在想打开一个文件，即 open("/foo/bar",O_RDONLY)

（1）文件系统首先要找到文件 bar 的 inode，但是现在只有完整的路径名。文件系统必须遍历路径名，从而找到所需的 inode。

（2）所有遍历都从文件系统的根开始，即根目录，记为 /。但是这个 inode 在哪呢？根的 inode 号必须是众所周知的。在大多数 UNIX 系统中，根的 inode 号为 2。

（3）文件系统读取根目录的 inode 之后，查找其中存储的数据块的内容，寻找 foo 的条目。

（4）然后递归遍历路径名，直到找到所需的 inode。

（5）文件系统定位到 bar 的 inode 之后，做权限检查。之后，为该进程分配一个文件描述符，并返回给用户。

（6）文件打开后，程序可以发出 read 系统调用，从文件中读取

（7）读取完成后，文件描述符被释放

文件的写入：

与读取类似，文件必须先打开。与读取不同，写入文件可能会分配一个块（除非块被覆盖）。

要创建一个文件，文件系统不仅要分配一个 inode，还要在包含新文件的目录中分配空间。写入的工作量很大：
（1）一个读取 inode 位图（查找空闲的 inode）
（2）一个写入 inode 位图（标记为已分配）
（3）一个写入新的 inode 本身（初始化 inode）
（4）一个写入目录的数据（将文件的高级名称链接到它的 inode 号）
（5）一个文件 inode 以便更新它

因为文件读写昂贵，会导致磁盘多次磁盘 IO，这是巨大的性能问题。大多数文件系统积极使用系统内存来缓存重要的块。

除了缓存，还可以使用写缓冲：通过延迟写入，文件系统可以将一些更新变成批量（多次更新其实只有最后一次有效），从而减少 IO 次数。

# 本书定律一览

### 1. Lampson 定律：做正确的事

重要的是做对事。抽象和简化都不能替代做对事。

有时你必须做正确的事，当你这样做时，总是好过其他方案。

### 2. Ousterhout 定律：避免魔法值

尽可能避免巫毒常量。即避免设置魔法值。

巫毒常量，举例来说，比如多级反馈队列中，设置的优先级重置的时间 S。

### 3. Lauer 定律：代码越少越好

程序员倾向于吹嘘自己使用大量的代码实现某功能。这样做本质是不对的。

我们应该吹嘘以很少的代码实现给定的任务。

简洁的代码更易懂，缺陷更少。

### 4. Knuth 定律：避免不成熟的优化

不成熟的优化是万恶之源。

先构建正确的程序。如果发现性能问题，那么就改进方法，只要优化到满足需求即可。

### 5. Hill 定律：简单的笨办法可能更好

某些时候，简单的自旋锁反而是最有效的，因为容易实现而且高效。

虽然读写锁听起来很酷，但是却很复杂，复杂可能意味着慢。

因此，总是优先尝试简单的笨办法。

### 6. Tom West 定律：不要总是完美

不是所有值得做的事情都值得做好。

如果坏事很少发生，并且造成的影响很小，那么我们不应该去花费大量的精力去预防它。

### 7. Livny 定律：总是视情况而定

在工程中，事实证明视情况而定几乎总是答案，这反映了取舍是工程师生活的一部分。

### 8. Patterson 定律：先测量后构建

先测量系统揭示问题，然后再构建新系统来修复所述问题。

通过使用实验数据而不是直觉，可以将系统构建过程变成更科学的尝试。

这样做时，可以保证：

首先，你有证据表明你正在解决一个真正的问题

第二，你现在有办法测量新系统，以显示它确实改进了
