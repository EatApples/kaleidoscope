### Linux 性能优化

来源：《极客时间》专栏之《Linux 性能优化实战》

主讲人：倪朋飞

### 性能问题的本质

系统资源达到瓶颈，请求的处理还不够快，无法支撑更多的请求

### 性能分析

找出应用或系统的瓶颈，给出解决方案

### uptime 显示的平均负载

单位时间内，系统平均活跃进程数（可运行状态，不可中断状态），与 CPU 使用率没有关系。理想的情况是等于 CPU 的个数（CPU 个数通过 cat /proc/cpuinfo 查看）

### 平均负载与 CPU 使用率

CPU 密集型进程，两者一致。IO 密集型进程，平均负载高，CPU 使用率不一定高

### CPU 上下文切换

进程上下文切换，线程上下文切换，中断上下文切换。

线程与进程大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。

自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。

非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。

自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题；非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈；中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型

### 系统调用

由用户态切换成内核态。一次系统调用，发生 2 次 CPU 上下文切换（call and ret）。系统调用过程通常称为特权模式切换，而不是上下文切换

### 中断

为了快速响应硬件事件，中断处理会打断进程的正常调度和执行。中断处理比进程拥有更高的优先级。通过 cat /proc/interrupts 查看。

中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行。中断处理程序在响应中断时，还会临时关闭中断。这就会导致上一次中断处理完成之前，其他中断都不能响应，也就是说中断有可能会丢失

### 中断处理程序

Linux 中的中断处理程序分为上半部和下半部：上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行；而下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。/proc/softirqs 提供了软中断的运行情况；/proc/interrupts 提供了硬中断的运行情况。

### 软中断

Linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型，可以通过查看 /proc/softirqs 来观察软中断的运行情况。TIMER（定时中断）、 NET_RX（网络接收）、SCHED（内核调度）、RCU（RCU 锁）

### 进程状态

运行（R：Running 或 Runnable）、空闲（I：Idle）、不可中断睡眠（D：Disk Sleep，Uninterruptible
Sleep）、可中断睡眠（S：Interruptible Sleep）、僵尸（Z：Zombie）、暂停（T：Stopped/Traced）、消亡（X：Dead）

### 不可中断状态

表示进程正在跟硬件交互，为了保护进程数据和硬件的一致性，系统不允许其他进程或中断打断这个进程。进程长时间处于不可中断状态，通常表示系统有 IO 性能问题

### 僵尸进程

表示进程已退出，但它的父进程还没有回收子进程占用的资源。短暂的僵尸进程不必理会，但长时间的僵尸进程通常是因为应用程序没有正常处理子进程的退出。解决方案：找出父进程，在父进程中解决

### 内存映射

其实就是将虚拟内存地址映射到物理内存地址。

为了完成内存映射，内核为每个进程都维护了一张页表，记录虚拟地址与物理地址的映射关系。为了解决页表项过多的问题，Linux 提供了两种机制，也就是多级页表和大页（HugePage）

在发现内存紧张时，系统就会通过一系列机制来回收内存，比如下面这三种方式：
回收缓存，比如使用 LRU（Least Recently Used）算法，回收最近使用最少的内存页面；
回收不常访问的内存，把不常用的内存通过交换分区直接写到磁盘中；
杀死进程，内存紧张时系统还会通过 OOM（Out of Memory），直接杀掉占用大量内存的进程。

### Buffers

是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大 （20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等。

### Cached

是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。

### buffer 与 cache

简单来说，Buffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中。在读写普通文件时，I/O 请求会首先经过文件系统，然后由文件系统负责，来与磁盘进行交互。而在读写块设备文件时，会跳过文件系统，直接与磁盘交互，也就是所谓的“裸 I/O”

内存中提到的 Buffer ，都跟块设备直接相关；而其他的都是 Cache。

### Linux 的 Swap 机制

Swap 把这些不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了

### 索引节点

简称为 inode，用来记录文件的元数据，比如 inode 编号、文件大小、访问权限、修改日期、数据的位置等。索引节点和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中。所以记住，索引节点同样占用磁盘空间。

### 目录项

简称为 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的关联关系。多个关联的目录项，就构成了文件系统的目录结构。不过，不同于索引节点，目录项是由内核维护的一个内存数据结构，所以通常也被叫做目录项缓存

### inode 与 dentry

换句话说，索引节点是每个文件的唯一标志，而目录项维护的正是文件系统的树状结构。 目录项和索引节点的关系是多对一，你可以简单理解为，一个文件可以有多个别名

### 逻辑块

磁盘读写的最小单位是扇区，然而扇区只有 512B 大小，如果每次都读写这么小的单位，效率一定很低。所以，文件系统又把连续的扇区组成了逻辑块，然后每次都以逻辑块为最小单元，来管理数据。常见的逻辑块大小为 4KB，也就是由连续的 8 个扇区组成

### Linux 文件系统的四大基本要

磁盘在执行文件系统格式化时，会被分成三个存储区域，超级块、索引节点区和数据块区。

超级块，存储整个文件系统的状态。
索引节点区，用来存储索引节点。
数据块区，则用来存储文件数据。

目录项、索引节点、逻辑块以及超级块，构成了 Linux 文件系统的四大基本要素。

### I/O 的分类

最常见的有，缓冲与非缓冲 I/O、 直接与非直接 I/O、阻塞与非阻塞 I/O、同步与异步 I/O 等。

第一种，根据是否利用标准库缓存，可以把文件 I/O 分为缓冲 I/O 与非缓冲 I/O。
缓冲 I/O，是指利用标准库缓存来加速文件的访问，而标准库内部再通过系统调度访问文件。
非缓冲 I/O，是指直接通过系统调用来访问文件，不再经过标准库缓存。

第二，根据是否利用操作系统的页缓存，可以把文件 I/O 分为直接 I/O 与非直接 I/O。
直接 I/O，是指跳过操作系统的页缓存，直接跟文件系统交互来访问文件。
非直接 I/O 正好相反，文件读写时，先要经过系统的页缓存，然后再由内核或额外的系统调用，真正写入磁盘。

第三，根据应用程序是否阻塞自身运行，可以把文件 I/O 分为阻塞 I/O 和非阻塞 I/O。
所谓阻塞 I/O，是指应用程序执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程，自然就不能执行其他任务。
所谓非阻塞 I/O，是指应用程序执行 I/O 操作后，不会阻塞当前的线程，可以继续执行 其他的任务，随后再通过轮询或者事件通知的形式，获取调用的结果。

第四，根据是否等待响应结果，可以把文件 I/O 分为同步和异步 I/O。
所谓同步 I/O，是指应用程序执行 I/O 操作后，要一直等到整个 I/O 完成后，才能获得 I/O 响应。
所谓异步 I/O，是指应用程序执行 I/O 操作后，不用等待完成和完成后的响应，而是继续执行就可以。等到这次 I/O 完成后，响应会用事件通知的方式，告诉应用程序。

### 虚拟文件系统 VFS

文件系统，是对存储设备上的文件进行组织管理的一种机制。为了支持各类不同的文件系 统，Linux 在各种文件系统上，抽象了一层虚拟文件系统 VFS。

它定义了一组所有文件系统都支持的数据结构和标准接口。这样，应用程序和内核中的其 他子系统，就只需要跟 VFS 提供的统一接口进行交互

### 通用块层

通用块层，为文件系统和应用程序提供了访问块设备的标准接口；同时，为各种块设备的驱动程序提供了统一的框架。此外，通用块层还会对文件系统和应用程序发送过来的 I/O 请求进行排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。

通用块层的下一层，自然就是设备层了，包括各种块设备的驱动程序以及物理存储设备。

### Linux 的存储 I/O 栈

文件系统、通用块层以及设备层，就构成了 Linux 的存储 I/O 栈。存储系统的 I/O ，通常是整个系统中最慢的一环。所以，Linux 采用多种缓存机制，来优化 I/O 的效率

### 半连接与全连接

所谓半连接，就是还没有完成 TCP 三次握手的连接，连接只进行了一半，而服务器收到了客户端的 SYN 包后，就会把这个连接放到半连接队列中，然后再向客户端发送 SYN+ACK 包

而全连接，则是指服务器收到了客户端的 ACK，完成了 TCP 三次握手，然后就会把这个连接挪到全连接队列中。这些全连接中的套接字，还需要再被 accept() 系统调用取走，这样，服务器就可以开始真正处理客户端的请求了。

### 水平触发和边缘触发

水平触发：只要文件描述符可以非阻塞地执行 I/O ，就会触发通知。也就是说，应用程序可以随时检查文件描述符的状态，然后再根据状态，进行 I/O 操作。

边缘触发：只有在文件描述符的状态发生改变（也就是 I/O 请求达到）时，才发送一次通知。这时候，应用程序需要尽可能多地执行 I/O，直到无法继续读写，才可以停止。 如果 I/O 没执行完，或者因为某种原因没来得及处理，那么这次通知也就丢失了。

### DNS 服务

DNS 服务通过资源记录的方式，来管理所有数据，它支持 A、CNAME、MX、 NS、PTR 等多种类型的记录。比如：
A 记录，用来把域名转换成 IP 地址；
CNAME 记录，用来创建别名；
而 NS 记录，则表示该域名对应的域名服务器地址。

### DDoS 攻击

DDoS 可以分为下面几种类型：
第一种，耗尽带宽。无论是服务器还是路由器、交换机等网络设备，带宽都有固定的上限。带宽耗尽后，就会发生网络拥堵，从而无法传输其他正常的网络报文。

第二种，耗尽操作系统的资源。网络服务的正常运行，都需要一定的系统资源，像是 CPU、内存等物理资源，以及连接表等软件资源。一旦资源耗尽，系统就不能处理其他正常的网络连接。

第三种，消耗应用程序的运行资源。应用程序的运行，通常还需要跟其他的资源或系统交互。如果应用程序一直忙于处理无效请求，也会导致正常请求的处理变慢，甚至得不到响应。

TCP SYN Cookies 也是一种专门防御 SYN Flood 攻击的方法。

### TCP 延迟确认

延迟确认是针对 TCP ACK 的一种优化机制，也就是说，不用每次请求都发送一个 ACK，而是先等一会儿（比如 40ms），看看有没有“顺风车”。如果这段时间内，正好有其他包需要发送，那就捎带着 ACK 一起发送过去。当然，如果一直等不到其他包，那就超时后单独发送 ACK。

### Nagle 算法（纳格算法）

Nagle 算法，是 TCP 协议中用于减少小包发送数量的一种优化算法，目的是为了提高实际带宽的利用率。

它通过合并 TCP 小包，提高网络带宽的利用率。 Nagle 算法规定，一个 TCP 连接上，最多只能有一个未被确认的未完成分组；在收到这个分组的 ACK 前，不发送其他分组。这些小分组会被组合起来，并在收到 ACK 后，用同一个分组发送出去。

### 网络地址转换

网络地址转换（Network Address Translation），缩写为 NAT。
NAT 技术可以重写 IP 数据包的源 IP 或者目的 IP，被普遍地用来解决公网 IP 地址短缺的 问题。它的主要原理就是，网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网 资源。同时，由于 NAT 屏蔽了内网网络，自然也就为局域网中的机器提供了安全隔离。

静态 NAT，即内网 IP 与公网 IP 是一对一的永久映射关系；
动态 NAT，即内网 IP 从公网 IP 池中，动态选择一个进行映射；
网络地址端口转换 NAPT（Network Address and Port Translation），即把内网 IP 映 射到公网 IP 的不同端口上，让多个内网 IP 可以共享同一个公网 IP 地址。

### 三个特殊的进程

0 号进程为 idle 进程，这也是系统创建的第一个进程，它在初始化 1 号和 2 号进程后，演变为空闲任务。当 CPU 上没有其他任务执行时，就会运行它。
1 号进程为 init 进程，通常是 systemd 进程，在用户态运行，用来管理其他用户态进程。
2 号进程为 kthreadd 进程，在内核态运行，用来管理内核线程。

### 性能监控的 USE 法 与 RED 法

专门用于性能监控的 USE（Utilization Saturation and Errors）法。 USE 法把系统资源的性能指标，简化成了三个类别，即使用率、饱和度以及错误数。

使用率，表示资源用于服务的时间或容量百分比。100% 的使用率，表示容量已经用尽或者全部时间都用于服务。
饱和度，表示资源的繁忙程度，通常与等待队列的长度相关。100% 的饱和度，表示资源无法接受更多的请求。
错误数表示发生错误的事件个数。错误数越多，表明系统的问题越严重。

对微服务来说，监控它们的请求数（Rate）、错误数（Errors）以及响应时间 （Duration）。所以，RED 方法适用于微服务应用的监控，而 USE 方法适用于系统资源的监控。

### 分析工具包：sysstat，bcc

mpstat：CPU 性能分析工具，查看每个 CPU 性能指标
pidstat：进程性能分析工具，查看进程 CPU、内存、IO、上下文切换
vmstat：系统性能分析工具，查看系统的内存、CPU 上下文切换和中断次数
perf：Linux 系统 2.6.31 之后内置的性能分析工具
execsnoop：专为短时进程设计的工具
dstat：同时查看 CPU 和 IO 的使用情况
strace：跟踪进程系统调用
sar：是一个系统活动报告工具，既可以实时查看系统的当前活动，又可以配置保存和报告历史统计数据
hping3：是一个可以构造 TCP/IP 协议数据包的工具，可以对系统进行安全审计、防火墙 测试等
tcpdump：是一个常用的网络抓包工具，常用来分析各种网络问题
cachestat：提供了整个操作系统缓存的读写命中情况。
cachetop：提供了每个进程的缓存命中情况
memleak：可以跟踪系统或指定进程的内存分配、释放请求，然后定期输出一个未释放内存和相应调用栈的汇总情况 （默认 5 秒）
iostat：是最常用的磁盘 I/O 性能观测工具，它提供了每个磁盘的使用率、IOPS、吞吐量等 各种常见的性能指标，当然，这些指标实际上来自 /proc/diskstats
lsof：专门用来查看进程打开文件列表，不过，这里的“文件”不只有普通文件，还包括了目 录、块设备、动态库、网络套接字等。
filetop：它是 bcc 软件包的一部分，基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，主要跟踪内核中文件的读写情况，并 输出线程 ID（TID）、读写大小、读写类型以及文件名称
opensnoop：它同属于 bcc 软件包，可以动态跟踪内核中的 open 系统调用
ifconfig 或者 ip 命令：来查看网络的配置。推荐使用 ip 工具，因为它提供了更丰富的功能和更易用的接口
ss：使用 ss 来查询网络的连接信息，因为它比 netstat 提供了更好的性能（速度更快）
nslookup：就可以查询到这个域名的 A 记录。另外一个常用的 DNS 解析工具 dig ，就提供了 trace 功能，可以展示递归查询的整个过程
tcpdump：仅支持命令行格式使用，常用在服务器中抓取和分析网络包

### IO 问题排查

磁盘和文件系统的 I/O ，通常是整个系统中慢的一个模块。
I/O 角度来分析，最开始的分析思路基本上类似，都是：

1. 先用 iostat 发现磁盘 I/O 性能瓶颈；
2. 再借助 pidstat ，定位出导致瓶颈的进程；
3. 随后分析进程的 I/O 行为；
4. 最后，结合应用程序的原理，分析这些 I/O 的来源。

### I/O 性能优化

从应用程序、文件系统以及磁盘角度，分别看看 I/O 性能优化的基本思路。

应用程序优化：
第一，可以用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。
第二，可以借助缓存 I/O ，充分利用系统缓存，降低实际 I/O 的次数。
第三，可以在应用程序内部构建自己的缓存，或者用 Redis 这类外部缓存系统
第四，在需要频繁读写同一块磁盘空间时，可以用 mmap 代替 read/write，减少内存的拷贝次数
第五，在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘， 即可以用 fsync() 取代 O_SYNC
第六，在多个应用程序共享相同磁盘时，为了保证 I/O 不被某个应用完全占用，推荐你使 用 cgroups 的 I/O 子系统，来限制进程 / 进程组的 IOPS 以及吞吐量
最后，在使用 CFQ 调度器时，可以用 ionice 来调整进程的 I/O 调度优先级，特别是提高 核心应用的 I/O 优先级

文件系统优化：
第一，你可以根据实际负载场景的不同，选择适合的文件系统
第二，在选好文件系统后，还可以进一步优化文件系统的配置选项
第三，可以优化文件系统的缓存
最后，在不需要持久化时，你还可以用内存文件系统 tmpfs，以获得更好的 I/O 性能

磁盘优化：
第一，简单有效的优化方法，就是换用性能更好的磁盘，比如用 SSD 替代 HDD
第二，我们可以使用 RAID ，把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列。 这样做既可以提高数据的可靠性，又可以提升数据的访问性能
第三，针对磁盘和应用程序 I/O 模式的特征，我们可以选择适合的 I/O 调度算法
第四，我们可以对应用程序的数据，进行磁盘级别的隔离
第五，在顺序读比较多的场景中，我们可以增大磁盘的预读数据
第六，我们可以优化内核块设备 I/O 的选项
最后，要注意，磁盘本身出现硬件错误，也会导致 I/O 性能急剧下降

### 阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系

阻塞 / 非阻塞和同步 / 异步，其实就是两个不同角度的 I/O 划分方式。

它们描述的对象也不同，阻塞 / 非阻塞针对的是 I/O 调用者（即应用程序），而同步 / 异步针对的是 I/O 执行者（即系统）。

在网络套接字的接口中，使用 send() 直接向套接字发送数据时，如果套接字没有设置 O_NONBLOCK 标识，那 么 send() 操作就会一直阻塞，当前线程也没法去做其他事情。当然，如果你用了 epoll，系统会告诉你这个套接字的状态，那就可以用非阻塞的方式 使用。当这个套接字不可写的时候，你可以去做其他事情，比如读写其他套接字。

比如在 Linux I/O 调用中，系统调用 read 是同步读，所以，在没有得到磁盘数据前，read 不会响应应用程序。而 aio_read 是异步读，系统收到 AIO 读请求后不等处理就返回了，而具体的 read 结果，再通过回调异步通知应用程序。

### 同名进程的 PID 一直在变，CPU 飚高，但是 top 没有发现

（1）进程在不停的奔溃重启，启动过程资源初始化，可能占用高 CPU
（2）进程是短时进程，也就是在其他应用内部通过 exec 调用的外面命令

### 使用 root 账户运行 strace 命令失败，报没有权限

一般遇到这种问题，先检查进程的状态是否正常，使用 ps 命令，发现进程已经变成僵尸

### 性能优化方法论

首先，既然要做性能优化，那要怎么判断它是不是有效呢？特别是优化后，到底能提升多少性能呢？

1. 确定性能的量化指标
2. 测试优化前的性能指标
3. 测试优化后的性能指标

第二，性能问题通常不是独立的，如果有多个性能问题同时发生，你应该先优化哪一个呢？

在性能测试的领域，流传很广的一个说法是“二八原则”，也就是说 80% 的问题都是由 20% 的代码导致的。只要找出这 20% 的位置，你就可以优化 80% 的性能。所以，并不是所有的性能问题都值得优化

第三，提升性能的方法并不是唯一的，当有多种方法可以选择时，你会选用哪一种呢？ 是不是总选那个大程度提升性能的方法就行了呢？
性能优化并非没有成本。

编译器优化：很多编译器都会提供优化选项，适当开启它们，在编译阶段你就可以获得编译器的帮助，来提升性能。比如， gcc 就提供了优化选项 -O2，开启后会自动对应用程序的代码进行优化。

算法优化：使用复杂度更低的算法，可以显著加快处理速度。比如，在数据比较大的情况下，可以用 O(nlogn) 的排序算法（如快排、归并排序等），代替 O(n^2) 的排序算

异步处理：使用异步处理，可以避免程序因为等待某个资源而一直阻塞，从而提升程序的并发处理能力。比如，把轮询替换为事件通知，就可以避免轮询耗费 CPU 的问题。

多线程代替多进程：前面讲过，相对于进程的上下文切换，线程的上下文切换并不切换进程地址空间，因此可以降低上下文切换的成本。

善用缓存：经常访问的数据或者计算过程中的步骤，可以放到内存中缓存起来，这样在下次用时就能直接从内存中获取，加快程序的处理速度

### I/O 模型优化

第一种，使用非阻塞 I/O 和水平触发通知，比如使用 select 或者 poll。这种方式的大优点，是对应用程序比较友好，它的 API 非常简单。但是，应用软件使用 select 和 poll 时，需要对这些文件描述符列表进行轮询，这样，请求数多的时候就会比较耗时。除此之外，应用程序每次调用 select 和 poll 时，还需要把文件描述符的集合，从用户空间传入内核空间，由内核修改后，再传出到用户空间中。这一来一回的内核空间与用户空间切换，也增加了处理成本。

第二种，使用非阻塞 I/O 和边缘触发通知，比如 epoll。epoll 使用红黑树，在内核中管理文件描述符的集合，这样，就不需要应用程序在每次操作时都传入、传出这个集合。epoll 使用事件驱动的机制，只关注有 I/O 事件发生的文件描述符，不需要轮询扫描整个集合。由于边缘触发只在文件描述符可读或可写事件发生时才通知，那么应用程序就需要尽可能多地执行 I/O，并要处理更多的异常事件。

第三种，使用异步 I/O（Asynchronous I/O，简称为 AIO）。异步 I/O 允许应用程序同时发起很多 I/O 操作，而不用等待这些操作完成。而在 I/O 完成后，系统会用事件通知（比如信号或者回调函数）的方式，告诉应用程序。这时，应用程序才会去查询 I/O 操作的结果。异步 I/O 也是到了 Linux 2.6 才支持的功能，并且在很长时间里都处于不完善的状态，比如 glibc 提供的异步 I/O 库，就一直被社区诟病。同时，由于异步 I/O 跟我们的直观逻辑不太一样，想要使用的话，一定要小心设计，其使用难度比较高。

### 工作模型优化

使用 I/O 多路复用后，就可以在一个进程或线程中处理多个请求，其中，又有下面两种不同的工作模型。

第一种，主进程 + 多个 worker 子进程，这也是最常用的一种模型。这种方法的一个通用工作模式就是：主进程执行 bind() + listen() 后，创建多个子进程；然后，在每个子进程中，都通过 accept() 或 epoll_wait() ，来处理相同的套接字。常用的反向代理服务器 Nginx 就是这么工作的。为了避免惊群问题， Nginx 在每个 worker 进程中，都增加一个了全局锁 （accept_mutex）。

第二种，监听到相同端口的多进程模型。在这种方式下，所有的进程都监听相同的接口， 并且开启 SO_REUSEPORT 选项，由内核负责将请求负载均衡到这些监听进程中去。由于内核确保了只有一个进程被唤醒，就不会出现惊群问题了。

### C10K/C1000K/C10M 问题

C10K 问题的根源，一方面在于系统有限的资源；另一方面，也是更重要的因素，是同步阻塞的 I/O 模型以及轮询的套接字接口，限制了网络事件的处理效率。Linux 2.6 中引入 的 epoll ，完美解决了 C10K 的问题，现在的高性能网络方案都基于 epoll。

从 C10K 到 C100K ，可能只需要增加系统的物理资源就可以满足；但从 C100K 到 C1000K ，就不仅仅是增加物理资源就能解决的问题了。这时，就需要多方面的优化工作 了，从硬件的中断处理和网络功能卸载、到网络协议栈的文件描述符数量、连接状态跟踪、缓存队列等内核的优化，再到应用程序的工作模型优化，都是考虑的重点。

再进一步，要实现 C10M ，就不只是增加物理资源，或者优化内核和应用程序可以解决的问题了。这时候，就需要用 XDP 的方式，在内核协议栈之前处理网络包；或者用 DPDK 直接跳过网络协议栈，在用户空间通过轮询的方式直接处理网络包。

当然了，实际上，在大多数场景中，我们并不需要单机并发 1000 万的请求。通过调整系统架构，把这些请求分发到多台服务器中来处理，通常是更简单和更容易扩展的方案。

### 网络性能的评估

在应用层，我们关注的是应用程序的并发连接数、每秒请求数、处理延迟、错误数等，可以使用 wrk、Jmeter 等工具，模拟用户的负载，得到想要的测试结果。

而在传输层，我们关注的是 TCP、UDP 等传输层协议的工作状况，比如 TCP 连接数、 TCP 重传、TCP 错误数等。此时，你可以使用 iperf、netperf 等，来测试 TCP 或 UDP 的性能。

再向下到网络层，我们关注的则是网络包的处理能力，即 PPS。Linux 内核自带的 pktgen，就可以帮你测试这个指标。

### DNS 解析不稳定

DNS 解析，说白了就是客户端与服务器交互的过程， 并且这个过程还使用了 UDP 协议。那么，对于整个流程来说，解析结果不稳定，就有很多种可能的情况了。比方说：
DNS 服务器本身有问题，响应慢并且不稳定；
或者是，客户端到 DNS 服务器的网络延迟比较大；
再或者，DNS 请求或者响应包，在某些情况下被链路中的网络设备弄丢了。

在你使用 ping 时，如果发现结果中的延迟并不大，而 ping 命令本身却很慢，不要 慌，有可能是背后的 PTR 在搞鬼（PTR 反向地址解析的目的，是从 IP 地址反查出域名）

### 网络延迟增大

在发现网络延迟增大后，你可以用 traceroute、hping3、tcpdump、Wireshark、 strace 等多种工具，来定位网络中的潜在问题。比如：
使用 hping3 以及 wrk 等工具，确认单次请求和并发请求情况的网络延迟是否正常。
使用 traceroute，确认路由是否正确，并查看路由中每一跳网关的延迟。
使用 tcpdump 和 Wireshark，确认网络包的收发是否正常。
使用 strace 等，观察应用程序对网络套接字的调用情况是否正常。
这样，你就可以依次从路由、网络包的收发、再到应用程序等，逐层排查，直到定位问题根源

### 网络性能优化

在应用程序中，主要是优化 I/O 模型、工作模型以及应用层的网络协议；
在套接字层中，主要是优化套接字的缓冲区大小；
在传输层中，主要是优化 TCP 和 UDP 协议；
在网络层中，主要是优化路由、转发、分片以及 ICMP 协议；
最后，在链路层中，主要是优化网络包的收发、网络功能卸载以及网卡选项。

### 丢包

可能发生丢包的位置，实际上贯穿了整个网络协议栈。
在两台 VM 连接之间，可能会发生传输失败的错误，比如网络拥塞、线路错误等；
在网卡收包后，环形缓冲区可能会因为溢出而丢包；
在链路层，可能会因为网络帧校验失败、QoS 等而丢包；
在 IP 层，可能会因为路由失败、组包大小超过 MTU 等而丢包；
在传输层，可能会因为端口未监听、资源占用超过内核限制等而丢包；
在套接字层，可能会因为套接字缓冲区溢出而丢包；
在应用层，可能会因为应用程序异常而丢包；
此外，如果配置了 iptables 规则，这些网络包也可能因为 iptables 过滤规则而丢包。

### 进阶书籍

Linux 基础入门书籍：《鸟哥的 Linux 私房菜》
计算机体系结构书籍：《深入理解计算机系统》
Linux 编程书籍：《Linux 程序设计》和《UNIX 环境高级编程》
Linux 内核书籍：《深入 Linux 内核架构》
性能优化书籍：《性能之巅：洞悉系统、企业与云计算》
计算机网络经典教材《计算机网络（第 5 版）》
网络协议必读书籍《TCP/IP 详解 卷 1：协议》
Wireshark 书籍《Wireshark 网络分析就这么简单》和《Wireshark 网络分析的艺术》
网络编程书籍《UNIX 网络编程》
